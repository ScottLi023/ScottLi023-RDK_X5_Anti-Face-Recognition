
import cv2
import numpy as np
import os
import time
from PIL import Image, ImageDraw, ImageFont
from flask import Flask, Response, render_template_string

# å¯¼å…¥ç°æœ‰æ¨¡å—
from utils.load_lib import FaceLiveness
from models.tflite_model import TFLiteFaceEngine
from face_recognition import load_registered_faces, compute_similarity

app = Flask(__name__)

# å…¨å±€å˜é‡
camera = None
liveness_detector = None
recognizer = None
registered_faces = {}

def cv2_add_chinese_text(img, text, position, text_color=(0, 255, 0), text_size=30):
    """
    ä½¿ç”¨PILåœ¨OpenCVå›¾åƒä¸Šç»˜åˆ¶ä¸­æ–‡
    """
    if (isinstance(img, np.ndarray)):
        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    
    draw = ImageDraw.Draw(img)
    
    # å°è¯•åŠ è½½ä¸­æ–‡å­—ä½“
    font_paths = [
        "simhei.ttf",  # å¸¸è§Windows/Linuxå­—ä½“
        "/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf", # Ubuntu/Debianå¸¸è§
        "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",   # Arch/Fedoraå¸¸è§
        "/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc"               # å¸¸è§å¼€æºä¸­æ–‡å­—ä½“
    ]
    
    font = None
    for path in font_paths:
        if os.path.exists(path):
            try:
                font = ImageFont.truetype(path, text_size)
                break
            except:
                continue
                
    if font is None:
        font = ImageFont.load_default()

    draw.text(position, text, fill=text_color, font=font)
    
    return cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)

def init_resources():
    global liveness_detector, recognizer, registered_faces, camera
    print("[INFO] æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
    
    try:
        # åˆå§‹åŒ–æ£€æµ‹å™¨ (ä½¿ç”¨ä¼˜åŒ–åçš„å†…å­˜æ¥å£)
        liveness_detector = FaceLiveness()
        
        # åˆå§‹åŒ–è¯†åˆ«å™¨ (MobileNetV3)
        rec_model_path = "/home/sunrise/Code/Anti-Face-Recognition/weights/mobilenetv3_small_mcp.tflite"
        recognizer = TFLiteFaceEngine(rec_model_path)
        
        # åŠ è½½æ³¨å†Œäººè„¸åº“
        registered_faces = load_registered_faces("registered_faces.pkl")
        if not registered_faces:
            print("[WARNING] äººè„¸åº“ä¸ºç©ºï¼Œæ‰€æœ‰äººå°†è¢«æ ‡è®°ä¸ºæœªçŸ¥èº«ä»½")

        # åˆå§‹åŒ–æ‘„åƒå¤´
        camera = cv2.VideoCapture(0)
        camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            
    except Exception as e:
        print(f"[ERROR] åˆå§‹åŒ–å¤±è´¥: {e}")
        return False
    return True

def generate_frames():
    global camera, liveness_detector, recognizer, registered_faces
    
    fps_count = 0
    fps_start = time.time()
    fps = 0

    while True:
        success, frame = camera.read()
        if not success:
            break
            
        # é•œåƒç¿»è½¬
        frame = cv2.flip(frame, 1)
        display_frame = frame.copy()

        # --- äººè„¸æ£€æµ‹ (ä½¿ç”¨å†…å­˜ç›´ä¼ æ¥å£) ---
        detected_faces = []
        try:
            detected_faces = liveness_detector.detect_from_frame(frame)
        except Exception as e:
            # å…¼å®¹æ—§æ¥å£çš„fallbackï¼Œå¦‚æœdetect_from_frameä¸å¯ç”¨
            # print(f"[WARNING] å†…å­˜æ£€æµ‹å¤±è´¥ï¼Œå°è¯•æ–‡ä»¶æ¨¡å¼: {e}")
            try:
                temp_path = "temp_flask_frame.jpg"
                cv2.imwrite(temp_path, frame)
                detected_faces = liveness_detector.detect(temp_path)
            except Exception as e2:
                print(f"[WARNING] æ£€æµ‹å¤±è´¥: {e2}")

        # --- å¤„ç†æ£€æµ‹ç»“æœ ---
        for face in detected_faces:
            # è¦æ±‚1: å‡è„¸ -> å¿½ç•¥ (ç›´æ¥æ˜¾ç¤ºåŸå›¾ï¼Œä¸ç»˜åˆ¶ä»»ä½•æ¡†)
            if not face['is_real']:
                continue

            # çœŸäººè„¸å¤„ç†
            bbox = face['bbox'] # [x, y, w, h]
            x, y, w, h = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])
            
            # ç‰¹å¾æå–
            landmarks = np.array(face['landmarks'], dtype=np.float32)
            embedding = recognizer.get_embedding(frame, landmarks)
            
            # èº«ä»½åŒ¹é…
            best_match_name = None
            max_similarity = 0.0
            threshold = 0.35
            
            for name, reg_embedding in registered_faces.items():
                similarity = compute_similarity(embedding, reg_embedding)
                if similarity > max_similarity:
                    max_similarity = similarity
                    best_match_name = name

            # ç»˜åˆ¶ç»“æœ
            if max_similarity > threshold:
                # è¦æ±‚2: çœŸäºº + å·²çŸ¥ -> ç»¿æ¡† + ä¸­æ–‡ä¿¡æ¯
                color = (0, 255, 0) # ç»¿è‰²
                cv2.rectangle(display_frame, (x, y), (x+w, y+h), color, 2)
                
                text_content = f"{best_match_name} ({max_similarity:.2f})"
                display_frame = cv2_add_chinese_text(
                    display_frame, 
                    text_content, 
                    (x, y - 35), 
                    text_color=color,
                    text_size=30
                )
            else:
                # è¦æ±‚3: çœŸäºº + æœªçŸ¥ -> çº¢æ¡†
                color = (0, 0, 255) # çº¢è‰²
                cv2.rectangle(display_frame, (x, y), (x+w, y+h), color, 2)

        # è®¡ç®—å¹¶æ˜¾ç¤ºFPS
        fps_count += 1
        if time.time() - fps_start > 1.0:
            fps = fps_count / (time.time() - fps_start)
            fps_count = 0
            fps_start = time.time()
        
        cv2.putText(display_frame, f"FPS: {fps:.1f}", (10, 30), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

        # ç¼–ç ä¸ºJPEGæµ
        ret, buffer = cv2.imencode('.jpg', display_frame)
        frame_bytes = buffer.tobytes()
        
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

@app.route('/')
def index():
    return render_template_string('''
        <html>
          <head>
            <title>å®æ—¶äººè„¸è¯†åˆ«ç›‘æ§</title>
            <style>
              body { background-color: #222; color: white; text-align: center; font-family: sans-serif; }
              h1 { margin-top: 20px; }
              .video-container { margin: 20px auto; border: 5px solid #444; display: inline-block; max-width: 100%; }
              img { width: 100%; max-width: 800px; height: auto; }
              .legend { margin-top: 10px; }
              .green { color: #00ff00; font-weight: bold; }
              .red { color: #ff0000; font-weight: bold; }
            </style>
          </head>
          <body>
            <h1>ğŸ“¸ å®æ—¶äººè„¸è¯†åˆ«ç›‘æ§ç³»ç»Ÿ</h1>
            <div class="video-container">
              <img src="{{ url_for('video_feed') }}">
            </div>
            <div class="legend">
              <p><span class="green">ç»¿è‰²è¾¹æ¡†</span>: å·²çŸ¥èº«ä»½ (çœŸäºº) &nbsp;|&nbsp; <span class="red">çº¢è‰²è¾¹æ¡†</span>: æœªçŸ¥èº«ä»½ (çœŸäºº)</p>
              <p>æ— è¾¹æ¡†: å‡è„¸ (ç…§ç‰‡/è§†é¢‘æ”»å‡») æˆ–è€… æœªæ£€æµ‹åˆ°äººè„¸</p>
            </div>
          </body>
        </html>
    ''')

@app.route('/video_feed')
def video_feed():
    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

def main():
    if init_resources():
        print("="*60)
        print("  WebæœåŠ¡å™¨å¯åŠ¨æˆåŠŸï¼")
        print("  è¯·è®¿é—®: http://0.0.0.0:5000")
        print("="*60)
        try:
            app.run(host='0.0.0.0', port=5000, debug=False, threaded=True)
        finally:
            if camera and camera.isOpened():
                camera.release()
            if liveness_detector:
                try:
                    liveness_detector.release()
                except:
                    pass
    else:
        print("[ERROR] ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")

if __name__ == "__main__":
    main()
